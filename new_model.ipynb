{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new_model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNijkgzXQGSvPYiDtypLZEq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2022Group3/projectNotebooks/blob/main/new_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-T16dTlEhMpn"
      },
      "outputs": [],
      "source": [
        "# baseline model with dropout and data augmentation on the cifar10 dataset\n",
        "import numpy as np\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9I0T-74hQGB",
        "outputId": "aadb5269-7c8d-4444-d0dd-bfbb228a0255"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "  data=np.load(r'drive/MyDrive/data_modified_new_labels.npz')\n",
        "  data=dict(zip((\"{}\".format(k) for k in data),(data[k] for k in data)))\n",
        "  trainX=data['train']\n",
        "  trainy=data['ytrain']\n",
        "  validationX=data['validation']\n",
        "  validationy=data['yvalidation']\n",
        "  testX=data['test']\n",
        "  testy=data['ytest']\n",
        "  return trainX,to_categorical(trainy),validationX,to_categorical(validationy),testX,to_categorical(testy)"
      ],
      "metadata": {
        "id": "tdln3sTKhQ0c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scale pixels\n",
        "def prep_pixels(train,validation,test):\n",
        "  # convert from integers to floats\n",
        "  train_norm = train.astype('float32')\n",
        "  validation_norm = validation.astype('float32')\n",
        "  test_norm=test.astype('float32')\n",
        "  # normalize to range 0-1\n",
        "  train_norm = train_norm / 255.0\n",
        "  validation_norm = validation / 255.0\n",
        "  # return normalized images\n",
        "  test_norm=test_norm/255.0\n",
        "  return train_norm, validation_norm,test_norm"
      ],
      "metadata": {
        "id": "E1rjBOaUhUYq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotmodelhistory(history): \n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(history.history['accuracy']) \n",
        "    axs[0].plot(history.history['val_accuracy']) \n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy') \n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].legend(['train', 'validate'], loc='upper left')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(history.history['loss']) \n",
        "    axs[1].plot(history.history['val_loss']) \n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss') \n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].legend(['train', 'validate'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    # list all data in history\n",
        "    print(history.history.keys())"
      ],
      "metadata": {
        "id": "ixDqPLwMhYDm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(15, activation='softmax'))\n",
        " \t# compile model\n",
        "\topt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "hzfbizGvhagP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='validation')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='validation')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')"
      ],
      "metadata": {
        "id": "lPYVmKn9hfq5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # run the test harness for evaluating a model\n",
        "# def run_test_harness():\n",
        "# \t# load dataset\n",
        "#   trainX, trainy,validationX,validationy, testX, testy = load_dataset()\n",
        "# \t# prepare pixel data\n",
        "#   trainX, validationX ,testX= prep_pixels(trainX, validationX,testX)\n",
        "# \t# define model\n",
        "#   model = define_model()\n",
        "# \t# create data generator\n",
        "#   datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "# \t# prepare iterator\n",
        "#   it_train = datagen.flow(trainX, trainy, batch_size=64)\n",
        "# \t# fit model\n",
        "#   steps = int(trainX.shape[0] / 64)\n",
        "#   history = model.fit(it_train, steps_per_epoch=steps, epochs=250, validation_data=(validationX, validationy), verbose=1)\n",
        "# \t# evaluate model\n",
        "#   _, acc = model.evaluate(testX, testy, verbose=1)\n",
        "#   print('> %.3f' % (acc * 100.0))\n",
        "# \t# learning curves\n",
        "#   summarize_diagnostics(history)\n",
        "# \t#save model\n",
        "#   model.save('/content/drive/MyDrive/new_model.h5')\n",
        "#   return model"
      ],
      "metadata": {
        "id": "hYt1C_mihi5_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness_b():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY,validationX, validationY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, validationX, testX = prep_pixels(trainX,validationX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\t# prepare iterator\n",
        "\tit_train = datagen.flow(trainX, trainY, batch_size=32)\n",
        "\t# fit model\n",
        "\tsteps = int(trainX.shape[0] /32)\n",
        "\thistory = model.fit(it_train, steps_per_epoch=steps, epochs=250, validation_data=(validationX, validationY), verbose=1)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(testX, testY, verbose=1)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "  # save\n",
        "\tmodel.save('/content/drive/MyDrive/new_model.h5')\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "7p4d-aqNoM1L"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# entry point, run the test harness\n",
        "model=run_test_harness_b()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GvZbJTMchleo",
        "outputId": "2cef46bf-99ff-4ecc-91f1-21b4a5bd02fe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 2.3712 - accuracy: 0.2686 - val_loss: 1.7031 - val_accuracy: 0.4203\n",
            "Epoch 2/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 1.8371 - accuracy: 0.3824 - val_loss: 1.7209 - val_accuracy: 0.4244\n",
            "Epoch 3/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 1.7065 - accuracy: 0.4295 - val_loss: 1.6297 - val_accuracy: 0.4515\n",
            "Epoch 4/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.6041 - accuracy: 0.4650 - val_loss: 1.5103 - val_accuracy: 0.4977\n",
            "Epoch 5/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.5289 - accuracy: 0.4915 - val_loss: 1.3870 - val_accuracy: 0.5341\n",
            "Epoch 6/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.4631 - accuracy: 0.5159 - val_loss: 1.3876 - val_accuracy: 0.5368\n",
            "Epoch 7/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.4084 - accuracy: 0.5339 - val_loss: 1.3593 - val_accuracy: 0.5520\n",
            "Epoch 8/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.3602 - accuracy: 0.5523 - val_loss: 1.3470 - val_accuracy: 0.5563\n",
            "Epoch 9/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.3179 - accuracy: 0.5648 - val_loss: 1.4477 - val_accuracy: 0.5329\n",
            "Epoch 10/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.2860 - accuracy: 0.5772 - val_loss: 1.2898 - val_accuracy: 0.5784\n",
            "Epoch 11/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.2489 - accuracy: 0.5909 - val_loss: 1.1414 - val_accuracy: 0.6245\n",
            "Epoch 12/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.2174 - accuracy: 0.5987 - val_loss: 1.1466 - val_accuracy: 0.6279\n",
            "Epoch 13/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1904 - accuracy: 0.6104 - val_loss: 1.1267 - val_accuracy: 0.6293\n",
            "Epoch 14/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1670 - accuracy: 0.6151 - val_loss: 1.0454 - val_accuracy: 0.6519\n",
            "Epoch 15/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1451 - accuracy: 0.6236 - val_loss: 1.1110 - val_accuracy: 0.6436\n",
            "Epoch 16/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1216 - accuracy: 0.6316 - val_loss: 1.0448 - val_accuracy: 0.6569\n",
            "Epoch 17/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1029 - accuracy: 0.6380 - val_loss: 0.9935 - val_accuracy: 0.6684\n",
            "Epoch 18/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0849 - accuracy: 0.6439 - val_loss: 0.9691 - val_accuracy: 0.6776\n",
            "Epoch 19/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0640 - accuracy: 0.6546 - val_loss: 0.9493 - val_accuracy: 0.6897\n",
            "Epoch 20/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0527 - accuracy: 0.6539 - val_loss: 1.0202 - val_accuracy: 0.6695\n",
            "Epoch 21/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0338 - accuracy: 0.6622 - val_loss: 0.8972 - val_accuracy: 0.7052\n",
            "Epoch 22/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0185 - accuracy: 0.6669 - val_loss: 0.8800 - val_accuracy: 0.7092\n",
            "Epoch 23/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0094 - accuracy: 0.6698 - val_loss: 0.9557 - val_accuracy: 0.6905\n",
            "Epoch 24/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9989 - accuracy: 0.6729 - val_loss: 0.9582 - val_accuracy: 0.6823\n",
            "Epoch 25/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9904 - accuracy: 0.6782 - val_loss: 0.8969 - val_accuracy: 0.7097\n",
            "Epoch 26/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9686 - accuracy: 0.6812 - val_loss: 0.8442 - val_accuracy: 0.7219\n",
            "Epoch 27/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9558 - accuracy: 0.6898 - val_loss: 0.8427 - val_accuracy: 0.7208\n",
            "Epoch 28/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9548 - accuracy: 0.6895 - val_loss: 0.9101 - val_accuracy: 0.7027\n",
            "Epoch 29/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9337 - accuracy: 0.6936 - val_loss: 0.8179 - val_accuracy: 0.7327\n",
            "Epoch 30/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9284 - accuracy: 0.6971 - val_loss: 0.8349 - val_accuracy: 0.7296\n",
            "Epoch 31/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9237 - accuracy: 0.6986 - val_loss: 0.8404 - val_accuracy: 0.7285\n",
            "Epoch 32/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9087 - accuracy: 0.7033 - val_loss: 0.7869 - val_accuracy: 0.7401\n",
            "Epoch 33/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9019 - accuracy: 0.7064 - val_loss: 0.7682 - val_accuracy: 0.7476\n",
            "Epoch 34/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.8897 - accuracy: 0.7126 - val_loss: 0.7626 - val_accuracy: 0.7487\n",
            "Epoch 35/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.8789 - accuracy: 0.7120 - val_loss: 0.8472 - val_accuracy: 0.7267\n",
            "Epoch 36/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.8705 - accuracy: 0.7159 - val_loss: 0.8026 - val_accuracy: 0.7387\n",
            "Epoch 37/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.8635 - accuracy: 0.7185 - val_loss: 0.7921 - val_accuracy: 0.7467\n",
            "Epoch 38/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.8586 - accuracy: 0.7199 - val_loss: 0.7869 - val_accuracy: 0.7433\n",
            "Epoch 39/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.8434 - accuracy: 0.7262 - val_loss: 0.8090 - val_accuracy: 0.7383\n",
            "Epoch 40/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.8394 - accuracy: 0.7271 - val_loss: 0.7363 - val_accuracy: 0.7641\n",
            "Epoch 41/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.8389 - accuracy: 0.7274 - val_loss: 0.7643 - val_accuracy: 0.7544\n",
            "Epoch 42/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.8301 - accuracy: 0.7327 - val_loss: 0.6965 - val_accuracy: 0.7767\n",
            "Epoch 43/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.8200 - accuracy: 0.7332 - val_loss: 0.7429 - val_accuracy: 0.7581\n",
            "Epoch 44/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.8158 - accuracy: 0.7360 - val_loss: 0.7263 - val_accuracy: 0.7609\n",
            "Epoch 45/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.8063 - accuracy: 0.7400 - val_loss: 0.7541 - val_accuracy: 0.7556\n",
            "Epoch 46/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7985 - accuracy: 0.7433 - val_loss: 0.6893 - val_accuracy: 0.7776\n",
            "Epoch 47/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7979 - accuracy: 0.7411 - val_loss: 0.7390 - val_accuracy: 0.7615\n",
            "Epoch 48/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7907 - accuracy: 0.7435 - val_loss: 0.6917 - val_accuracy: 0.7761\n",
            "Epoch 49/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7803 - accuracy: 0.7458 - val_loss: 0.7068 - val_accuracy: 0.7740\n",
            "Epoch 50/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7805 - accuracy: 0.7472 - val_loss: 0.6464 - val_accuracy: 0.7904\n",
            "Epoch 51/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7729 - accuracy: 0.7505 - val_loss: 0.6747 - val_accuracy: 0.7848\n",
            "Epoch 52/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7630 - accuracy: 0.7527 - val_loss: 0.7010 - val_accuracy: 0.7712\n",
            "Epoch 53/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7619 - accuracy: 0.7544 - val_loss: 0.6677 - val_accuracy: 0.7885\n",
            "Epoch 54/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7525 - accuracy: 0.7573 - val_loss: 0.6877 - val_accuracy: 0.7817\n",
            "Epoch 55/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 0.7515 - accuracy: 0.7569 - val_loss: 0.7064 - val_accuracy: 0.7753\n",
            "Epoch 56/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7487 - accuracy: 0.7564 - val_loss: 0.6787 - val_accuracy: 0.7824\n",
            "Epoch 57/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7423 - accuracy: 0.7597 - val_loss: 0.6579 - val_accuracy: 0.7931\n",
            "Epoch 58/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7332 - accuracy: 0.7619 - val_loss: 0.6624 - val_accuracy: 0.7896\n",
            "Epoch 59/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7266 - accuracy: 0.7658 - val_loss: 0.6827 - val_accuracy: 0.7817\n",
            "Epoch 60/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7231 - accuracy: 0.7649 - val_loss: 0.6615 - val_accuracy: 0.7945\n",
            "Epoch 61/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7172 - accuracy: 0.7668 - val_loss: 0.6521 - val_accuracy: 0.7959\n",
            "Epoch 62/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7178 - accuracy: 0.7678 - val_loss: 0.6711 - val_accuracy: 0.7895\n",
            "Epoch 63/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7151 - accuracy: 0.7680 - val_loss: 0.7055 - val_accuracy: 0.7799\n",
            "Epoch 64/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7157 - accuracy: 0.7699 - val_loss: 0.6588 - val_accuracy: 0.7915\n",
            "Epoch 65/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7031 - accuracy: 0.7718 - val_loss: 0.6960 - val_accuracy: 0.7773\n",
            "Epoch 66/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7094 - accuracy: 0.7719 - val_loss: 0.6255 - val_accuracy: 0.8036\n",
            "Epoch 67/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.7035 - accuracy: 0.7707 - val_loss: 0.6302 - val_accuracy: 0.7977\n",
            "Epoch 68/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6999 - accuracy: 0.7729 - val_loss: 0.6683 - val_accuracy: 0.7851\n",
            "Epoch 69/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6913 - accuracy: 0.7739 - val_loss: 0.6164 - val_accuracy: 0.8048\n",
            "Epoch 70/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6910 - accuracy: 0.7761 - val_loss: 0.6627 - val_accuracy: 0.7929\n",
            "Epoch 71/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6843 - accuracy: 0.7769 - val_loss: 0.6023 - val_accuracy: 0.8113\n",
            "Epoch 72/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6791 - accuracy: 0.7802 - val_loss: 0.6395 - val_accuracy: 0.7976\n",
            "Epoch 73/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6723 - accuracy: 0.7814 - val_loss: 0.5995 - val_accuracy: 0.8133\n",
            "Epoch 74/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6739 - accuracy: 0.7808 - val_loss: 0.6434 - val_accuracy: 0.7995\n",
            "Epoch 75/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6689 - accuracy: 0.7826 - val_loss: 0.6092 - val_accuracy: 0.8132\n",
            "Epoch 76/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6626 - accuracy: 0.7865 - val_loss: 0.5904 - val_accuracy: 0.8164\n",
            "Epoch 77/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6610 - accuracy: 0.7869 - val_loss: 0.6375 - val_accuracy: 0.8013\n",
            "Epoch 78/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6601 - accuracy: 0.7854 - val_loss: 0.5964 - val_accuracy: 0.8141\n",
            "Epoch 79/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6618 - accuracy: 0.7864 - val_loss: 0.6120 - val_accuracy: 0.8096\n",
            "Epoch 80/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6577 - accuracy: 0.7878 - val_loss: 0.6155 - val_accuracy: 0.8008\n",
            "Epoch 81/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6497 - accuracy: 0.7886 - val_loss: 0.6167 - val_accuracy: 0.8037\n",
            "Epoch 82/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6474 - accuracy: 0.7899 - val_loss: 0.5810 - val_accuracy: 0.8176\n",
            "Epoch 83/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6448 - accuracy: 0.7906 - val_loss: 0.6952 - val_accuracy: 0.7829\n",
            "Epoch 84/250\n",
            "1406/1406 [==============================] - 27s 20ms/step - loss: 0.6493 - accuracy: 0.7896 - val_loss: 0.5805 - val_accuracy: 0.8172\n",
            "Epoch 85/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6415 - accuracy: 0.7931 - val_loss: 0.5856 - val_accuracy: 0.8188\n",
            "Epoch 86/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6405 - accuracy: 0.7935 - val_loss: 0.6229 - val_accuracy: 0.8028\n",
            "Epoch 87/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6354 - accuracy: 0.7931 - val_loss: 0.5667 - val_accuracy: 0.8220\n",
            "Epoch 88/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6297 - accuracy: 0.7968 - val_loss: 0.6000 - val_accuracy: 0.8116\n",
            "Epoch 89/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6313 - accuracy: 0.7968 - val_loss: 0.5556 - val_accuracy: 0.8227\n",
            "Epoch 90/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6347 - accuracy: 0.7941 - val_loss: 0.5919 - val_accuracy: 0.8108\n",
            "Epoch 91/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6241 - accuracy: 0.7975 - val_loss: 0.5652 - val_accuracy: 0.8215\n",
            "Epoch 92/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6216 - accuracy: 0.7968 - val_loss: 0.6375 - val_accuracy: 0.7987\n",
            "Epoch 93/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6209 - accuracy: 0.7987 - val_loss: 0.5781 - val_accuracy: 0.8189\n",
            "Epoch 94/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6209 - accuracy: 0.8009 - val_loss: 0.5711 - val_accuracy: 0.8237\n",
            "Epoch 95/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6122 - accuracy: 0.8013 - val_loss: 0.5765 - val_accuracy: 0.8205\n",
            "Epoch 96/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6047 - accuracy: 0.8046 - val_loss: 0.5845 - val_accuracy: 0.8197\n",
            "Epoch 97/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6122 - accuracy: 0.8020 - val_loss: 0.5601 - val_accuracy: 0.8244\n",
            "Epoch 98/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6054 - accuracy: 0.8041 - val_loss: 0.5583 - val_accuracy: 0.8257\n",
            "Epoch 99/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6033 - accuracy: 0.8054 - val_loss: 0.5417 - val_accuracy: 0.8323\n",
            "Epoch 100/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6019 - accuracy: 0.8037 - val_loss: 0.6044 - val_accuracy: 0.8092\n",
            "Epoch 101/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5994 - accuracy: 0.8064 - val_loss: 0.5387 - val_accuracy: 0.8328\n",
            "Epoch 102/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5961 - accuracy: 0.8065 - val_loss: 0.5560 - val_accuracy: 0.8283\n",
            "Epoch 103/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5946 - accuracy: 0.8079 - val_loss: 0.5641 - val_accuracy: 0.8257\n",
            "Epoch 104/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5927 - accuracy: 0.8070 - val_loss: 0.5640 - val_accuracy: 0.8267\n",
            "Epoch 105/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.6000 - accuracy: 0.8070 - val_loss: 0.5553 - val_accuracy: 0.8295\n",
            "Epoch 106/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5876 - accuracy: 0.8085 - val_loss: 0.5425 - val_accuracy: 0.8333\n",
            "Epoch 107/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5809 - accuracy: 0.8109 - val_loss: 0.5514 - val_accuracy: 0.8301\n",
            "Epoch 108/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5917 - accuracy: 0.8086 - val_loss: 0.5400 - val_accuracy: 0.8340\n",
            "Epoch 109/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5830 - accuracy: 0.8112 - val_loss: 0.5817 - val_accuracy: 0.8235\n",
            "Epoch 110/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5828 - accuracy: 0.8098 - val_loss: 0.5744 - val_accuracy: 0.8216\n",
            "Epoch 111/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5829 - accuracy: 0.8104 - val_loss: 0.5349 - val_accuracy: 0.8375\n",
            "Epoch 112/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5763 - accuracy: 0.8130 - val_loss: 0.5470 - val_accuracy: 0.8269\n",
            "Epoch 113/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5773 - accuracy: 0.8120 - val_loss: 0.5463 - val_accuracy: 0.8327\n",
            "Epoch 114/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5788 - accuracy: 0.8118 - val_loss: 0.5588 - val_accuracy: 0.8251\n",
            "Epoch 115/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5698 - accuracy: 0.8146 - val_loss: 0.5442 - val_accuracy: 0.8300\n",
            "Epoch 116/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5641 - accuracy: 0.8160 - val_loss: 0.5425 - val_accuracy: 0.8341\n",
            "Epoch 117/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5685 - accuracy: 0.8145 - val_loss: 0.5338 - val_accuracy: 0.8328\n",
            "Epoch 118/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5691 - accuracy: 0.8163 - val_loss: 0.5148 - val_accuracy: 0.8371\n",
            "Epoch 119/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5754 - accuracy: 0.8127 - val_loss: 0.5328 - val_accuracy: 0.8365\n",
            "Epoch 120/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.5692 - accuracy: 0.8151 - val_loss: 0.5459 - val_accuracy: 0.8311\n",
            "Epoch 121/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5597 - accuracy: 0.8171 - val_loss: 0.5275 - val_accuracy: 0.8364\n",
            "Epoch 122/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.5601 - accuracy: 0.8168 - val_loss: 0.5387 - val_accuracy: 0.8335\n",
            "Epoch 123/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5628 - accuracy: 0.8167 - val_loss: 0.5058 - val_accuracy: 0.8429\n",
            "Epoch 124/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5571 - accuracy: 0.8191 - val_loss: 0.5437 - val_accuracy: 0.8317\n",
            "Epoch 125/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5496 - accuracy: 0.8207 - val_loss: 0.5633 - val_accuracy: 0.8240\n",
            "Epoch 126/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5591 - accuracy: 0.8198 - val_loss: 0.5444 - val_accuracy: 0.8299\n",
            "Epoch 127/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5543 - accuracy: 0.8202 - val_loss: 0.6394 - val_accuracy: 0.8056\n",
            "Epoch 128/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.5518 - accuracy: 0.8196 - val_loss: 0.5354 - val_accuracy: 0.8333\n",
            "Epoch 129/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5460 - accuracy: 0.8227 - val_loss: 0.5262 - val_accuracy: 0.8360\n",
            "Epoch 130/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.5528 - accuracy: 0.8208 - val_loss: 0.5535 - val_accuracy: 0.8293\n",
            "Epoch 131/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5414 - accuracy: 0.8233 - val_loss: 0.5483 - val_accuracy: 0.8315\n",
            "Epoch 132/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5449 - accuracy: 0.8233 - val_loss: 0.5074 - val_accuracy: 0.8427\n",
            "Epoch 133/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5444 - accuracy: 0.8247 - val_loss: 0.5585 - val_accuracy: 0.8269\n",
            "Epoch 134/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5445 - accuracy: 0.8203 - val_loss: 0.5408 - val_accuracy: 0.8344\n",
            "Epoch 135/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5338 - accuracy: 0.8263 - val_loss: 0.5164 - val_accuracy: 0.8420\n",
            "Epoch 136/250\n",
            "1406/1406 [==============================] - 27s 20ms/step - loss: 0.5359 - accuracy: 0.8258 - val_loss: 0.5339 - val_accuracy: 0.8392\n",
            "Epoch 137/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5363 - accuracy: 0.8259 - val_loss: 0.5177 - val_accuracy: 0.8423\n",
            "Epoch 138/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5321 - accuracy: 0.8274 - val_loss: 0.5371 - val_accuracy: 0.8364\n",
            "Epoch 139/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5363 - accuracy: 0.8254 - val_loss: 0.5529 - val_accuracy: 0.8304\n",
            "Epoch 140/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.5277 - accuracy: 0.8284 - val_loss: 0.5194 - val_accuracy: 0.8415\n",
            "Epoch 141/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5332 - accuracy: 0.8267 - val_loss: 0.5173 - val_accuracy: 0.8384\n",
            "Epoch 142/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5308 - accuracy: 0.8289 - val_loss: 0.5341 - val_accuracy: 0.8349\n",
            "Epoch 143/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.5184 - accuracy: 0.8306 - val_loss: 0.5141 - val_accuracy: 0.8457\n",
            "Epoch 144/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.5256 - accuracy: 0.8287 - val_loss: 0.5151 - val_accuracy: 0.8448\n",
            "Epoch 145/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5175 - accuracy: 0.8310 - val_loss: 0.5164 - val_accuracy: 0.8423\n",
            "Epoch 146/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.5238 - accuracy: 0.8295 - val_loss: 0.5161 - val_accuracy: 0.8428\n",
            "Epoch 147/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5230 - accuracy: 0.8300 - val_loss: 0.5280 - val_accuracy: 0.8392\n",
            "Epoch 148/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5250 - accuracy: 0.8307 - val_loss: 0.5198 - val_accuracy: 0.8443\n",
            "Epoch 149/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.5205 - accuracy: 0.8307 - val_loss: 0.5432 - val_accuracy: 0.8316\n",
            "Epoch 150/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5191 - accuracy: 0.8313 - val_loss: 0.5337 - val_accuracy: 0.8344\n",
            "Epoch 151/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.5203 - accuracy: 0.8306 - val_loss: 0.4908 - val_accuracy: 0.8463\n",
            "Epoch 152/250\n",
            "1406/1406 [==============================] - 27s 20ms/step - loss: 0.5148 - accuracy: 0.8325 - val_loss: 0.5212 - val_accuracy: 0.8415\n",
            "Epoch 153/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5144 - accuracy: 0.8337 - val_loss: 0.5068 - val_accuracy: 0.8437\n",
            "Epoch 154/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.5189 - accuracy: 0.8319 - val_loss: 0.5053 - val_accuracy: 0.8459\n",
            "Epoch 155/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5150 - accuracy: 0.8319 - val_loss: 0.5840 - val_accuracy: 0.8224\n",
            "Epoch 156/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5082 - accuracy: 0.8343 - val_loss: 0.5323 - val_accuracy: 0.8392\n",
            "Epoch 157/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.5133 - accuracy: 0.8330 - val_loss: 0.5246 - val_accuracy: 0.8388\n",
            "Epoch 158/250\n",
            "1406/1406 [==============================] - 27s 20ms/step - loss: 0.5051 - accuracy: 0.8360 - val_loss: 0.4983 - val_accuracy: 0.8469\n",
            "Epoch 159/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5054 - accuracy: 0.8351 - val_loss: 0.5016 - val_accuracy: 0.8469\n",
            "Epoch 160/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.5016 - accuracy: 0.8351 - val_loss: 0.5031 - val_accuracy: 0.8443\n",
            "Epoch 161/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4997 - accuracy: 0.8369 - val_loss: 0.4992 - val_accuracy: 0.8477\n",
            "Epoch 162/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5013 - accuracy: 0.8365 - val_loss: 0.4923 - val_accuracy: 0.8509\n",
            "Epoch 163/250\n",
            "1406/1406 [==============================] - 27s 20ms/step - loss: 0.4999 - accuracy: 0.8366 - val_loss: 0.5359 - val_accuracy: 0.8383\n",
            "Epoch 164/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4994 - accuracy: 0.8368 - val_loss: 0.4893 - val_accuracy: 0.8469\n",
            "Epoch 165/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4978 - accuracy: 0.8373 - val_loss: 0.5236 - val_accuracy: 0.8403\n",
            "Epoch 166/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 0.5015 - accuracy: 0.8361 - val_loss: 0.5593 - val_accuracy: 0.8320\n",
            "Epoch 167/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4960 - accuracy: 0.8389 - val_loss: 0.5126 - val_accuracy: 0.8436\n",
            "Epoch 168/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5018 - accuracy: 0.8375 - val_loss: 0.5067 - val_accuracy: 0.8451\n",
            "Epoch 169/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4922 - accuracy: 0.8408 - val_loss: 0.5082 - val_accuracy: 0.8460\n",
            "Epoch 170/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.5003 - accuracy: 0.8390 - val_loss: 0.5351 - val_accuracy: 0.8421\n",
            "Epoch 171/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4969 - accuracy: 0.8357 - val_loss: 0.4932 - val_accuracy: 0.8485\n",
            "Epoch 172/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4977 - accuracy: 0.8370 - val_loss: 0.4900 - val_accuracy: 0.8509\n",
            "Epoch 173/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 0.4944 - accuracy: 0.8378 - val_loss: 0.5050 - val_accuracy: 0.8455\n",
            "Epoch 174/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 0.4855 - accuracy: 0.8418 - val_loss: 0.5067 - val_accuracy: 0.8469\n",
            "Epoch 175/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4879 - accuracy: 0.8420 - val_loss: 0.4838 - val_accuracy: 0.8520\n",
            "Epoch 176/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 0.4910 - accuracy: 0.8406 - val_loss: 0.4976 - val_accuracy: 0.8492\n",
            "Epoch 177/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 0.4873 - accuracy: 0.8419 - val_loss: 0.4844 - val_accuracy: 0.8565\n",
            "Epoch 178/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4798 - accuracy: 0.8429 - val_loss: 0.5419 - val_accuracy: 0.8396\n",
            "Epoch 179/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4866 - accuracy: 0.8430 - val_loss: 0.4932 - val_accuracy: 0.8489\n",
            "Epoch 180/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4840 - accuracy: 0.8432 - val_loss: 0.4933 - val_accuracy: 0.8507\n",
            "Epoch 181/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4839 - accuracy: 0.8422 - val_loss: 0.5228 - val_accuracy: 0.8403\n",
            "Epoch 182/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4811 - accuracy: 0.8432 - val_loss: 0.5002 - val_accuracy: 0.8465\n",
            "Epoch 183/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4807 - accuracy: 0.8428 - val_loss: 0.5237 - val_accuracy: 0.8421\n",
            "Epoch 184/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4747 - accuracy: 0.8467 - val_loss: 0.4864 - val_accuracy: 0.8551\n",
            "Epoch 185/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4812 - accuracy: 0.8430 - val_loss: 0.5069 - val_accuracy: 0.8452\n",
            "Epoch 186/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4791 - accuracy: 0.8442 - val_loss: 0.4863 - val_accuracy: 0.8528\n",
            "Epoch 187/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4820 - accuracy: 0.8432 - val_loss: 0.4732 - val_accuracy: 0.8559\n",
            "Epoch 188/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4775 - accuracy: 0.8424 - val_loss: 0.5174 - val_accuracy: 0.8424\n",
            "Epoch 189/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4724 - accuracy: 0.8454 - val_loss: 0.5068 - val_accuracy: 0.8492\n",
            "Epoch 190/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4752 - accuracy: 0.8454 - val_loss: 0.5084 - val_accuracy: 0.8452\n",
            "Epoch 191/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4738 - accuracy: 0.8461 - val_loss: 0.4812 - val_accuracy: 0.8572\n",
            "Epoch 192/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4758 - accuracy: 0.8441 - val_loss: 0.5059 - val_accuracy: 0.8481\n",
            "Epoch 193/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4723 - accuracy: 0.8468 - val_loss: 0.5205 - val_accuracy: 0.8436\n",
            "Epoch 194/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4677 - accuracy: 0.8468 - val_loss: 0.5414 - val_accuracy: 0.8392\n",
            "Epoch 195/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4725 - accuracy: 0.8464 - val_loss: 0.4678 - val_accuracy: 0.8559\n",
            "Epoch 196/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4712 - accuracy: 0.8466 - val_loss: 0.4991 - val_accuracy: 0.8487\n",
            "Epoch 197/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4730 - accuracy: 0.8454 - val_loss: 0.4777 - val_accuracy: 0.8547\n",
            "Epoch 198/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4661 - accuracy: 0.8481 - val_loss: 0.4873 - val_accuracy: 0.8549\n",
            "Epoch 199/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4708 - accuracy: 0.8456 - val_loss: 0.4929 - val_accuracy: 0.8499\n",
            "Epoch 200/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4649 - accuracy: 0.8482 - val_loss: 0.4973 - val_accuracy: 0.8504\n",
            "Epoch 201/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4705 - accuracy: 0.8476 - val_loss: 0.4819 - val_accuracy: 0.8533\n",
            "Epoch 202/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4657 - accuracy: 0.8489 - val_loss: 0.4850 - val_accuracy: 0.8551\n",
            "Epoch 203/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4551 - accuracy: 0.8537 - val_loss: 0.5026 - val_accuracy: 0.8472\n",
            "Epoch 204/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4660 - accuracy: 0.8472 - val_loss: 0.4909 - val_accuracy: 0.8517\n",
            "Epoch 205/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4675 - accuracy: 0.8477 - val_loss: 0.4926 - val_accuracy: 0.8519\n",
            "Epoch 206/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 0.4573 - accuracy: 0.8532 - val_loss: 0.4972 - val_accuracy: 0.8472\n",
            "Epoch 207/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4634 - accuracy: 0.8491 - val_loss: 0.4917 - val_accuracy: 0.8497\n",
            "Epoch 208/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4590 - accuracy: 0.8509 - val_loss: 0.4692 - val_accuracy: 0.8601\n",
            "Epoch 209/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4642 - accuracy: 0.8503 - val_loss: 0.5152 - val_accuracy: 0.8476\n",
            "Epoch 210/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4587 - accuracy: 0.8500 - val_loss: 0.4896 - val_accuracy: 0.8544\n",
            "Epoch 211/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4568 - accuracy: 0.8515 - val_loss: 0.4844 - val_accuracy: 0.8571\n",
            "Epoch 212/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4552 - accuracy: 0.8518 - val_loss: 0.4789 - val_accuracy: 0.8555\n",
            "Epoch 213/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4525 - accuracy: 0.8527 - val_loss: 0.4879 - val_accuracy: 0.8553\n",
            "Epoch 214/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4578 - accuracy: 0.8490 - val_loss: 0.5181 - val_accuracy: 0.8483\n",
            "Epoch 215/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4546 - accuracy: 0.8527 - val_loss: 0.4881 - val_accuracy: 0.8524\n",
            "Epoch 216/250\n",
            "1406/1406 [==============================] - 27s 20ms/step - loss: 0.4591 - accuracy: 0.8506 - val_loss: 0.4723 - val_accuracy: 0.8571\n",
            "Epoch 217/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4536 - accuracy: 0.8526 - val_loss: 0.4812 - val_accuracy: 0.8579\n",
            "Epoch 218/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4547 - accuracy: 0.8516 - val_loss: 0.4844 - val_accuracy: 0.8573\n",
            "Epoch 219/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4492 - accuracy: 0.8529 - val_loss: 0.5080 - val_accuracy: 0.8491\n",
            "Epoch 220/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4456 - accuracy: 0.8546 - val_loss: 0.4637 - val_accuracy: 0.8611\n",
            "Epoch 221/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4495 - accuracy: 0.8532 - val_loss: 0.4774 - val_accuracy: 0.8555\n",
            "Epoch 222/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4525 - accuracy: 0.8535 - val_loss: 0.5182 - val_accuracy: 0.8456\n",
            "Epoch 223/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4493 - accuracy: 0.8542 - val_loss: 0.4512 - val_accuracy: 0.8652\n",
            "Epoch 224/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4505 - accuracy: 0.8550 - val_loss: 0.4900 - val_accuracy: 0.8525\n",
            "Epoch 225/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4455 - accuracy: 0.8545 - val_loss: 0.4868 - val_accuracy: 0.8541\n",
            "Epoch 226/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4507 - accuracy: 0.8529 - val_loss: 0.4925 - val_accuracy: 0.8508\n",
            "Epoch 227/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4524 - accuracy: 0.8522 - val_loss: 0.4657 - val_accuracy: 0.8576\n",
            "Epoch 228/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4446 - accuracy: 0.8549 - val_loss: 0.4851 - val_accuracy: 0.8543\n",
            "Epoch 229/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4464 - accuracy: 0.8538 - val_loss: 0.5317 - val_accuracy: 0.8415\n",
            "Epoch 230/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4428 - accuracy: 0.8543 - val_loss: 0.4776 - val_accuracy: 0.8541\n",
            "Epoch 231/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4468 - accuracy: 0.8549 - val_loss: 0.4714 - val_accuracy: 0.8588\n",
            "Epoch 232/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4365 - accuracy: 0.8580 - val_loss: 0.4726 - val_accuracy: 0.8621\n",
            "Epoch 233/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4432 - accuracy: 0.8559 - val_loss: 0.4797 - val_accuracy: 0.8583\n",
            "Epoch 234/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4447 - accuracy: 0.8547 - val_loss: 0.4603 - val_accuracy: 0.8611\n",
            "Epoch 235/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4372 - accuracy: 0.8593 - val_loss: 0.4894 - val_accuracy: 0.8543\n",
            "Epoch 236/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4440 - accuracy: 0.8556 - val_loss: 0.5015 - val_accuracy: 0.8489\n",
            "Epoch 237/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4419 - accuracy: 0.8567 - val_loss: 0.4660 - val_accuracy: 0.8595\n",
            "Epoch 238/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4372 - accuracy: 0.8566 - val_loss: 0.4710 - val_accuracy: 0.8584\n",
            "Epoch 239/250\n",
            "1406/1406 [==============================] - 27s 20ms/step - loss: 0.4376 - accuracy: 0.8574 - val_loss: 0.4657 - val_accuracy: 0.8623\n",
            "Epoch 240/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4371 - accuracy: 0.8551 - val_loss: 0.4863 - val_accuracy: 0.8544\n",
            "Epoch 241/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4320 - accuracy: 0.8582 - val_loss: 0.4762 - val_accuracy: 0.8583\n",
            "Epoch 242/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4300 - accuracy: 0.8601 - val_loss: 0.4560 - val_accuracy: 0.8597\n",
            "Epoch 243/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4387 - accuracy: 0.8574 - val_loss: 0.4968 - val_accuracy: 0.8509\n",
            "Epoch 244/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4337 - accuracy: 0.8588 - val_loss: 0.4894 - val_accuracy: 0.8529\n",
            "Epoch 245/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4302 - accuracy: 0.8594 - val_loss: 0.4607 - val_accuracy: 0.8584\n",
            "Epoch 246/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4346 - accuracy: 0.8557 - val_loss: 0.4841 - val_accuracy: 0.8557\n",
            "Epoch 247/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4318 - accuracy: 0.8588 - val_loss: 0.4887 - val_accuracy: 0.8544\n",
            "Epoch 248/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.4330 - accuracy: 0.8586 - val_loss: 0.4975 - val_accuracy: 0.8483\n",
            "Epoch 249/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4227 - accuracy: 0.8611 - val_loss: 0.4959 - val_accuracy: 0.8515\n",
            "Epoch 250/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.4315 - accuracy: 0.8581 - val_loss: 0.4932 - val_accuracy: 0.8521\n",
            "704/704 [==============================] - 3s 4ms/step - loss: 0.4648 - accuracy: 0.8531\n",
            "> 85.307\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
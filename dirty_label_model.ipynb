{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dirty_label_model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNqZlyO+fOQGNr4nskCW2BB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2022Group3/projectNotebooks/blob/main/dirty_label_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-T16dTlEhMpn"
      },
      "outputs": [],
      "source": [
        "# baseline model with dropout and data augmentation on the cifar10 dataset\n",
        "import numpy as np\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9I0T-74hQGB",
        "outputId": "d82d2fb4-65ad-45f9-a66b-f90be24a84d4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "  data=np.load(r'drive/MyDrive/data_modified_new_labels.npz')\n",
        "  data=dict(zip((\"{}\".format(k) for k in data),(data[k] for k in data)))\n",
        "  trainX=data['train']\n",
        "  trainy=data['ytrain']\n",
        "  validationX=data['validation']\n",
        "  validationy=data['yvalidation']\n",
        "  testX=data['test']\n",
        "  testy=data['ytest']\n",
        "  return trainX,trainy,validationX,to_categorical(validationy),testX,to_categorical(testy)"
      ],
      "metadata": {
        "id": "tdln3sTKhQ0c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scale pixels\n",
        "def prep_pixels(train,validation,test):\n",
        "  # convert from integers to floats\n",
        "  train_norm = train.astype('float32')\n",
        "  validation_norm = validation.astype('float32')\n",
        "  test_norm=test.astype('float32')\n",
        "  # normalize to range 0-1\n",
        "  train_norm = train_norm / 255.0\n",
        "  validation_norm = validation / 255.0\n",
        "  # return normalized images\n",
        "  test_norm=test_norm/255.0\n",
        "  return train_norm, validation_norm,test_norm"
      ],
      "metadata": {
        "id": "E1rjBOaUhUYq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotmodelhistory(history): \n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(history.history['accuracy']) \n",
        "    axs[0].plot(history.history['val_accuracy']) \n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy') \n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].legend(['train', 'validate'], loc='upper left')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(history.history['loss']) \n",
        "    axs[1].plot(history.history['val_loss']) \n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss') \n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].legend(['train', 'validate'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    # list all data in history\n",
        "    print(history.history.keys())"
      ],
      "metadata": {
        "id": "ixDqPLwMhYDm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(15, activation='softmax'))\n",
        " \t# compile model\n",
        "\topt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "hzfbizGvhagP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='validation')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='validation')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')"
      ],
      "metadata": {
        "id": "lPYVmKn9hfq5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # run the test harness for evaluating a model\n",
        "# def run_test_harness():\n",
        "# \t# load dataset\n",
        "#   trainX, trainy,validationX,validationy, testX, testy = load_dataset()\n",
        "# \t# prepare pixel data\n",
        "#   trainX, validationX ,testX= prep_pixels(trainX, validationX,testX)\n",
        "# \t# define model\n",
        "#   model = define_model()\n",
        "# \t# create data generator\n",
        "#   datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "# \t# prepare iterator\n",
        "#   it_train = datagen.flow(trainX, trainy, batch_size=64)\n",
        "# \t# fit model\n",
        "#   steps = int(trainX.shape[0] / 64)\n",
        "#   history = model.fit(it_train, steps_per_epoch=steps, epochs=250, validation_data=(validationX, validationy), verbose=1)\n",
        "# \t# evaluate model\n",
        "#   _, acc = model.evaluate(testX, testy, verbose=1)\n",
        "#   print('> %.3f' % (acc * 100.0))\n",
        "# \t# learning curves\n",
        "#   summarize_diagnostics(history)\n",
        "# \t#save model\n",
        "#   model.save('/content/drive/MyDrive/new_model.h5')\n",
        "#   return model"
      ],
      "metadata": {
        "id": "hYt1C_mihi5_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness_b():\n",
        "    # load dataset\n",
        "    trainX, trainY,validationX, validationY, testX, testY = load_dataset()\n",
        "  #dirty labels\n",
        "    percents=10\n",
        "    len_percents=int(len(trainY)*(percents/100))\n",
        "    random_indexes=np.random.randint(0,len(trainY),len_percents)\n",
        "    for i in random_indexes:\n",
        "      trainY[i]=np.random.randint(0,15)\n",
        "    trainY=to_categorical(trainY)\n",
        "    # prepare pixel data\n",
        "    trainX, validationX, testX = prep_pixels(trainX,validationX, testX)\n",
        "    # define model\n",
        "    model = define_model()\n",
        "    # create data generator\n",
        "    datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "    # prepare iterator\n",
        "    it_train = datagen.flow(trainX, trainY, batch_size=32)\n",
        "    # fit model\n",
        "    steps = int(trainX.shape[0] /32)\n",
        "    history = model.fit(it_train, steps_per_epoch=steps, epochs=250, validation_data=(validationX, validationY), verbose=1)\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate(testX, testY, verbose=1)\n",
        "    print('> %.3f' % (acc * 100.0))\n",
        "    # learning curves\n",
        "    summarize_diagnostics(history)\n",
        "    # save\n",
        "    model.save('/content/drive/MyDrive/dirty_label_model.h5')\n",
        "    return model"
      ],
      "metadata": {
        "id": "7p4d-aqNoM1L"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# entry point, run the test harness\n",
        "model=run_test_harness_b()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GvZbJTMchleo",
        "outputId": "5a4776ed-f577-4e74-9c4a-023379568229"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "1406/1406 [==============================] - 39s 19ms/step - loss: 2.5638 - accuracy: 0.2213 - val_loss: 1.8385 - val_accuracy: 0.3927\n",
            "Epoch 2/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 2.1028 - accuracy: 0.3249 - val_loss: 1.7392 - val_accuracy: 0.4136\n",
            "Epoch 3/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.9851 - accuracy: 0.3657 - val_loss: 1.6491 - val_accuracy: 0.4412\n",
            "Epoch 4/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.9137 - accuracy: 0.3921 - val_loss: 1.6936 - val_accuracy: 0.4467\n",
            "Epoch 5/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.8588 - accuracy: 0.4181 - val_loss: 1.5677 - val_accuracy: 0.4813\n",
            "Epoch 6/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.8160 - accuracy: 0.4337 - val_loss: 1.5538 - val_accuracy: 0.4825\n",
            "Epoch 7/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.7691 - accuracy: 0.4549 - val_loss: 1.5927 - val_accuracy: 0.4773\n",
            "Epoch 8/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.7343 - accuracy: 0.4692 - val_loss: 1.5136 - val_accuracy: 0.5063\n",
            "Epoch 9/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.7100 - accuracy: 0.4795 - val_loss: 1.4320 - val_accuracy: 0.5277\n",
            "Epoch 10/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.6835 - accuracy: 0.4908 - val_loss: 1.3516 - val_accuracy: 0.5583\n",
            "Epoch 11/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.6553 - accuracy: 0.5019 - val_loss: 1.3253 - val_accuracy: 0.5683\n",
            "Epoch 12/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.6304 - accuracy: 0.5125 - val_loss: 1.2660 - val_accuracy: 0.5855\n",
            "Epoch 13/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.6118 - accuracy: 0.5175 - val_loss: 1.2583 - val_accuracy: 0.5933\n",
            "Epoch 14/250\n",
            "1406/1406 [==============================] - 26s 18ms/step - loss: 1.5891 - accuracy: 0.5286 - val_loss: 1.2211 - val_accuracy: 0.6015\n",
            "Epoch 15/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.5724 - accuracy: 0.5328 - val_loss: 1.1674 - val_accuracy: 0.6264\n",
            "Epoch 16/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.5567 - accuracy: 0.5425 - val_loss: 1.2116 - val_accuracy: 0.6015\n",
            "Epoch 17/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.5385 - accuracy: 0.5493 - val_loss: 1.1504 - val_accuracy: 0.6289\n",
            "Epoch 18/250\n",
            "1406/1406 [==============================] - 26s 18ms/step - loss: 1.5277 - accuracy: 0.5557 - val_loss: 1.1643 - val_accuracy: 0.6260\n",
            "Epoch 19/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.5088 - accuracy: 0.5625 - val_loss: 1.1025 - val_accuracy: 0.6424\n",
            "Epoch 20/250\n",
            "1406/1406 [==============================] - 26s 18ms/step - loss: 1.4942 - accuracy: 0.5664 - val_loss: 1.0829 - val_accuracy: 0.6500\n",
            "Epoch 21/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.4820 - accuracy: 0.5713 - val_loss: 1.1546 - val_accuracy: 0.6268\n",
            "Epoch 22/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.4708 - accuracy: 0.5762 - val_loss: 1.0376 - val_accuracy: 0.6595\n",
            "Epoch 23/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.4606 - accuracy: 0.5777 - val_loss: 1.0365 - val_accuracy: 0.6668\n",
            "Epoch 24/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.4479 - accuracy: 0.5860 - val_loss: 0.9946 - val_accuracy: 0.6767\n",
            "Epoch 25/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.4314 - accuracy: 0.5921 - val_loss: 1.0318 - val_accuracy: 0.6629\n",
            "Epoch 26/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.4278 - accuracy: 0.5921 - val_loss: 0.9834 - val_accuracy: 0.6856\n",
            "Epoch 27/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.4160 - accuracy: 0.6001 - val_loss: 0.9757 - val_accuracy: 0.6857\n",
            "Epoch 28/250\n",
            "1406/1406 [==============================] - 26s 18ms/step - loss: 1.4143 - accuracy: 0.5975 - val_loss: 0.9811 - val_accuracy: 0.6839\n",
            "Epoch 29/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.4033 - accuracy: 0.6022 - val_loss: 0.9560 - val_accuracy: 0.6893\n",
            "Epoch 30/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.3958 - accuracy: 0.6075 - val_loss: 0.9688 - val_accuracy: 0.6855\n",
            "Epoch 31/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.3793 - accuracy: 0.6121 - val_loss: 0.9829 - val_accuracy: 0.6864\n",
            "Epoch 32/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.3718 - accuracy: 0.6147 - val_loss: 0.9120 - val_accuracy: 0.7049\n",
            "Epoch 33/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.3614 - accuracy: 0.6173 - val_loss: 0.9400 - val_accuracy: 0.6955\n",
            "Epoch 34/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.3594 - accuracy: 0.6189 - val_loss: 0.8846 - val_accuracy: 0.7173\n",
            "Epoch 35/250\n",
            "1406/1406 [==============================] - 26s 18ms/step - loss: 1.3576 - accuracy: 0.6214 - val_loss: 0.9455 - val_accuracy: 0.6992\n",
            "Epoch 36/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.3412 - accuracy: 0.6241 - val_loss: 0.9528 - val_accuracy: 0.6971\n",
            "Epoch 37/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.3399 - accuracy: 0.6264 - val_loss: 0.8772 - val_accuracy: 0.7257\n",
            "Epoch 38/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.3324 - accuracy: 0.6285 - val_loss: 0.8876 - val_accuracy: 0.7171\n",
            "Epoch 39/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.3280 - accuracy: 0.6318 - val_loss: 0.9016 - val_accuracy: 0.7133\n",
            "Epoch 40/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.3237 - accuracy: 0.6331 - val_loss: 0.8609 - val_accuracy: 0.7264\n",
            "Epoch 41/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.3105 - accuracy: 0.6374 - val_loss: 0.8519 - val_accuracy: 0.7253\n",
            "Epoch 42/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.3071 - accuracy: 0.6390 - val_loss: 0.8371 - val_accuracy: 0.7325\n",
            "Epoch 43/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.2974 - accuracy: 0.6414 - val_loss: 0.8469 - val_accuracy: 0.7328\n",
            "Epoch 44/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.2954 - accuracy: 0.6461 - val_loss: 0.8283 - val_accuracy: 0.7348\n",
            "Epoch 45/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.2930 - accuracy: 0.6448 - val_loss: 0.8217 - val_accuracy: 0.7409\n",
            "Epoch 46/250\n",
            "1406/1406 [==============================] - 26s 18ms/step - loss: 1.2883 - accuracy: 0.6441 - val_loss: 0.8238 - val_accuracy: 0.7376\n",
            "Epoch 47/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.2746 - accuracy: 0.6511 - val_loss: 0.8169 - val_accuracy: 0.7411\n",
            "Epoch 48/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.2818 - accuracy: 0.6496 - val_loss: 0.8431 - val_accuracy: 0.7332\n",
            "Epoch 49/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.2741 - accuracy: 0.6509 - val_loss: 0.8045 - val_accuracy: 0.7493\n",
            "Epoch 50/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.2640 - accuracy: 0.6539 - val_loss: 0.7806 - val_accuracy: 0.7580\n",
            "Epoch 51/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.2627 - accuracy: 0.6550 - val_loss: 0.7828 - val_accuracy: 0.7507\n",
            "Epoch 52/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.2575 - accuracy: 0.6560 - val_loss: 0.7991 - val_accuracy: 0.7459\n",
            "Epoch 53/250\n",
            "1406/1406 [==============================] - 26s 18ms/step - loss: 1.2558 - accuracy: 0.6588 - val_loss: 0.7901 - val_accuracy: 0.7516\n",
            "Epoch 54/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.2479 - accuracy: 0.6628 - val_loss: 0.7827 - val_accuracy: 0.7513\n",
            "Epoch 55/250\n",
            "1406/1406 [==============================] - 26s 18ms/step - loss: 1.2316 - accuracy: 0.6664 - val_loss: 0.7808 - val_accuracy: 0.7543\n",
            "Epoch 56/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.2349 - accuracy: 0.6670 - val_loss: 0.8194 - val_accuracy: 0.7425\n",
            "Epoch 57/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.2327 - accuracy: 0.6659 - val_loss: 0.7804 - val_accuracy: 0.7572\n",
            "Epoch 58/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.2293 - accuracy: 0.6689 - val_loss: 0.7592 - val_accuracy: 0.7651\n",
            "Epoch 59/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.2331 - accuracy: 0.6694 - val_loss: 0.7432 - val_accuracy: 0.7672\n",
            "Epoch 60/250\n",
            "1406/1406 [==============================] - 26s 18ms/step - loss: 1.2215 - accuracy: 0.6728 - val_loss: 0.7768 - val_accuracy: 0.7563\n",
            "Epoch 61/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.2168 - accuracy: 0.6725 - val_loss: 0.7763 - val_accuracy: 0.7580\n",
            "Epoch 62/250\n",
            "1406/1406 [==============================] - 26s 18ms/step - loss: 1.2147 - accuracy: 0.6736 - val_loss: 0.7355 - val_accuracy: 0.7673\n",
            "Epoch 63/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.2093 - accuracy: 0.6764 - val_loss: 0.7489 - val_accuracy: 0.7660\n",
            "Epoch 64/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.2058 - accuracy: 0.6756 - val_loss: 0.7361 - val_accuracy: 0.7697\n",
            "Epoch 65/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1981 - accuracy: 0.6779 - val_loss: 0.7354 - val_accuracy: 0.7687\n",
            "Epoch 66/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1941 - accuracy: 0.6802 - val_loss: 0.7336 - val_accuracy: 0.7701\n",
            "Epoch 67/250\n",
            "1406/1406 [==============================] - 26s 18ms/step - loss: 1.1920 - accuracy: 0.6818 - val_loss: 0.7361 - val_accuracy: 0.7687\n",
            "Epoch 68/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.1934 - accuracy: 0.6805 - val_loss: 0.7245 - val_accuracy: 0.7744\n",
            "Epoch 69/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1839 - accuracy: 0.6841 - val_loss: 0.7322 - val_accuracy: 0.7728\n",
            "Epoch 70/250\n",
            "1406/1406 [==============================] - 26s 18ms/step - loss: 1.1842 - accuracy: 0.6855 - val_loss: 0.7486 - val_accuracy: 0.7680\n",
            "Epoch 71/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.1827 - accuracy: 0.6846 - val_loss: 0.7299 - val_accuracy: 0.7744\n",
            "Epoch 72/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.1815 - accuracy: 0.6862 - val_loss: 0.7084 - val_accuracy: 0.7795\n",
            "Epoch 73/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1753 - accuracy: 0.6882 - val_loss: 0.7356 - val_accuracy: 0.7719\n",
            "Epoch 74/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.1695 - accuracy: 0.6879 - val_loss: 0.6928 - val_accuracy: 0.7847\n",
            "Epoch 75/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1712 - accuracy: 0.6903 - val_loss: 0.7193 - val_accuracy: 0.7743\n",
            "Epoch 76/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1629 - accuracy: 0.6912 - val_loss: 0.6826 - val_accuracy: 0.7847\n",
            "Epoch 77/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1625 - accuracy: 0.6921 - val_loss: 0.6893 - val_accuracy: 0.7860\n",
            "Epoch 78/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1647 - accuracy: 0.6930 - val_loss: 0.7099 - val_accuracy: 0.7807\n",
            "Epoch 79/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1572 - accuracy: 0.6945 - val_loss: 0.6975 - val_accuracy: 0.7831\n",
            "Epoch 80/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1548 - accuracy: 0.6939 - val_loss: 0.6883 - val_accuracy: 0.7840\n",
            "Epoch 81/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1472 - accuracy: 0.6986 - val_loss: 0.6986 - val_accuracy: 0.7848\n",
            "Epoch 82/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.1460 - accuracy: 0.6985 - val_loss: 0.6775 - val_accuracy: 0.7924\n",
            "Epoch 83/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1484 - accuracy: 0.6990 - val_loss: 0.7001 - val_accuracy: 0.7827\n",
            "Epoch 84/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1413 - accuracy: 0.6992 - val_loss: 0.6814 - val_accuracy: 0.7863\n",
            "Epoch 85/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1388 - accuracy: 0.7003 - val_loss: 0.6834 - val_accuracy: 0.7857\n",
            "Epoch 86/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.1366 - accuracy: 0.7015 - val_loss: 0.6629 - val_accuracy: 0.7936\n",
            "Epoch 87/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1320 - accuracy: 0.7031 - val_loss: 0.6757 - val_accuracy: 0.7933\n",
            "Epoch 88/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1299 - accuracy: 0.7049 - val_loss: 0.6730 - val_accuracy: 0.7908\n",
            "Epoch 89/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1325 - accuracy: 0.7018 - val_loss: 0.6800 - val_accuracy: 0.7887\n",
            "Epoch 90/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1285 - accuracy: 0.7025 - val_loss: 0.6525 - val_accuracy: 0.8007\n",
            "Epoch 91/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 1.1267 - accuracy: 0.7024 - val_loss: 0.6650 - val_accuracy: 0.7951\n",
            "Epoch 92/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 1.1183 - accuracy: 0.7075 - val_loss: 0.6462 - val_accuracy: 0.8004\n",
            "Epoch 93/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1207 - accuracy: 0.7072 - val_loss: 0.6460 - val_accuracy: 0.8023\n",
            "Epoch 94/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.1134 - accuracy: 0.7114 - val_loss: 0.6571 - val_accuracy: 0.7955\n",
            "Epoch 95/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1150 - accuracy: 0.7073 - val_loss: 0.6536 - val_accuracy: 0.7959\n",
            "Epoch 96/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1089 - accuracy: 0.7088 - val_loss: 0.6834 - val_accuracy: 0.7848\n",
            "Epoch 97/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1112 - accuracy: 0.7089 - val_loss: 0.6292 - val_accuracy: 0.8069\n",
            "Epoch 98/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1149 - accuracy: 0.7097 - val_loss: 0.6555 - val_accuracy: 0.7944\n",
            "Epoch 99/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1083 - accuracy: 0.7096 - val_loss: 0.6304 - val_accuracy: 0.8061\n",
            "Epoch 100/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1019 - accuracy: 0.7133 - val_loss: 0.6632 - val_accuracy: 0.7953\n",
            "Epoch 101/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.1014 - accuracy: 0.7131 - val_loss: 0.6306 - val_accuracy: 0.8077\n",
            "Epoch 102/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0958 - accuracy: 0.7151 - val_loss: 0.6752 - val_accuracy: 0.7875\n",
            "Epoch 103/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0963 - accuracy: 0.7152 - val_loss: 0.6296 - val_accuracy: 0.8053\n",
            "Epoch 104/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0976 - accuracy: 0.7139 - val_loss: 0.6317 - val_accuracy: 0.8079\n",
            "Epoch 105/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0937 - accuracy: 0.7130 - val_loss: 0.6373 - val_accuracy: 0.8023\n",
            "Epoch 106/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 1.0863 - accuracy: 0.7176 - val_loss: 0.6273 - val_accuracy: 0.8081\n",
            "Epoch 107/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0929 - accuracy: 0.7158 - val_loss: 0.6318 - val_accuracy: 0.8017\n",
            "Epoch 108/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0776 - accuracy: 0.7202 - val_loss: 0.6443 - val_accuracy: 0.8021\n",
            "Epoch 109/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0881 - accuracy: 0.7176 - val_loss: 0.6207 - val_accuracy: 0.8092\n",
            "Epoch 110/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0819 - accuracy: 0.7195 - val_loss: 0.6121 - val_accuracy: 0.8148\n",
            "Epoch 111/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0767 - accuracy: 0.7193 - val_loss: 0.6397 - val_accuracy: 0.8023\n",
            "Epoch 112/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0766 - accuracy: 0.7206 - val_loss: 0.6099 - val_accuracy: 0.8149\n",
            "Epoch 113/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0760 - accuracy: 0.7215 - val_loss: 0.6240 - val_accuracy: 0.8097\n",
            "Epoch 114/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0703 - accuracy: 0.7231 - val_loss: 0.6249 - val_accuracy: 0.8069\n",
            "Epoch 115/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0714 - accuracy: 0.7217 - val_loss: 0.6104 - val_accuracy: 0.8137\n",
            "Epoch 116/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0703 - accuracy: 0.7219 - val_loss: 0.6162 - val_accuracy: 0.8100\n",
            "Epoch 117/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0697 - accuracy: 0.7239 - val_loss: 0.6034 - val_accuracy: 0.8144\n",
            "Epoch 118/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0663 - accuracy: 0.7251 - val_loss: 0.6212 - val_accuracy: 0.8060\n",
            "Epoch 119/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0657 - accuracy: 0.7244 - val_loss: 0.6191 - val_accuracy: 0.8105\n",
            "Epoch 120/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0644 - accuracy: 0.7255 - val_loss: 0.6134 - val_accuracy: 0.8129\n",
            "Epoch 121/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 1.0582 - accuracy: 0.7278 - val_loss: 0.6252 - val_accuracy: 0.8061\n",
            "Epoch 122/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 1.0576 - accuracy: 0.7256 - val_loss: 0.6095 - val_accuracy: 0.8112\n",
            "Epoch 123/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0625 - accuracy: 0.7280 - val_loss: 0.6237 - val_accuracy: 0.8061\n",
            "Epoch 124/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.0576 - accuracy: 0.7271 - val_loss: 0.6159 - val_accuracy: 0.8113\n",
            "Epoch 125/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0556 - accuracy: 0.7299 - val_loss: 0.6193 - val_accuracy: 0.8064\n",
            "Epoch 126/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0562 - accuracy: 0.7301 - val_loss: 0.6091 - val_accuracy: 0.8112\n",
            "Epoch 127/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0500 - accuracy: 0.7278 - val_loss: 0.6001 - val_accuracy: 0.8167\n",
            "Epoch 128/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0573 - accuracy: 0.7291 - val_loss: 0.5996 - val_accuracy: 0.8148\n",
            "Epoch 129/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0479 - accuracy: 0.7319 - val_loss: 0.6183 - val_accuracy: 0.8085\n",
            "Epoch 130/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0455 - accuracy: 0.7326 - val_loss: 0.5870 - val_accuracy: 0.8163\n",
            "Epoch 131/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0453 - accuracy: 0.7301 - val_loss: 0.6013 - val_accuracy: 0.8140\n",
            "Epoch 132/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0459 - accuracy: 0.7335 - val_loss: 0.5958 - val_accuracy: 0.8180\n",
            "Epoch 133/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0354 - accuracy: 0.7346 - val_loss: 0.6353 - val_accuracy: 0.8081\n",
            "Epoch 134/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0403 - accuracy: 0.7323 - val_loss: 0.5791 - val_accuracy: 0.8232\n",
            "Epoch 135/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0387 - accuracy: 0.7337 - val_loss: 0.5987 - val_accuracy: 0.8161\n",
            "Epoch 136/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.0339 - accuracy: 0.7354 - val_loss: 0.5861 - val_accuracy: 0.8184\n",
            "Epoch 137/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0363 - accuracy: 0.7344 - val_loss: 0.6011 - val_accuracy: 0.8141\n",
            "Epoch 138/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 1.0392 - accuracy: 0.7341 - val_loss: 0.5823 - val_accuracy: 0.8241\n",
            "Epoch 139/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 1.0319 - accuracy: 0.7337 - val_loss: 0.5902 - val_accuracy: 0.8192\n",
            "Epoch 140/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.0253 - accuracy: 0.7375 - val_loss: 0.5943 - val_accuracy: 0.8184\n",
            "Epoch 141/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0300 - accuracy: 0.7358 - val_loss: 0.5913 - val_accuracy: 0.8173\n",
            "Epoch 142/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.0293 - accuracy: 0.7349 - val_loss: 0.5971 - val_accuracy: 0.8161\n",
            "Epoch 143/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.0250 - accuracy: 0.7396 - val_loss: 0.5967 - val_accuracy: 0.8133\n",
            "Epoch 144/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0247 - accuracy: 0.7380 - val_loss: 0.5780 - val_accuracy: 0.8229\n",
            "Epoch 145/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0254 - accuracy: 0.7384 - val_loss: 0.6236 - val_accuracy: 0.8075\n",
            "Epoch 146/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0215 - accuracy: 0.7390 - val_loss: 0.5614 - val_accuracy: 0.8256\n",
            "Epoch 147/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.0209 - accuracy: 0.7383 - val_loss: 0.5855 - val_accuracy: 0.8163\n",
            "Epoch 148/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.0200 - accuracy: 0.7387 - val_loss: 0.5820 - val_accuracy: 0.8200\n",
            "Epoch 149/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0144 - accuracy: 0.7414 - val_loss: 0.5611 - val_accuracy: 0.8273\n",
            "Epoch 150/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0184 - accuracy: 0.7385 - val_loss: 0.5787 - val_accuracy: 0.8204\n",
            "Epoch 151/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0137 - accuracy: 0.7423 - val_loss: 0.5920 - val_accuracy: 0.8144\n",
            "Epoch 152/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0170 - accuracy: 0.7419 - val_loss: 0.5798 - val_accuracy: 0.8237\n",
            "Epoch 153/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.0117 - accuracy: 0.7427 - val_loss: 0.5730 - val_accuracy: 0.8199\n",
            "Epoch 154/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.0103 - accuracy: 0.7410 - val_loss: 0.5617 - val_accuracy: 0.8280\n",
            "Epoch 155/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0119 - accuracy: 0.7423 - val_loss: 0.5918 - val_accuracy: 0.8157\n",
            "Epoch 156/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.0106 - accuracy: 0.7425 - val_loss: 0.5959 - val_accuracy: 0.8125\n",
            "Epoch 157/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0043 - accuracy: 0.7436 - val_loss: 0.5700 - val_accuracy: 0.8225\n",
            "Epoch 158/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.0071 - accuracy: 0.7436 - val_loss: 0.5779 - val_accuracy: 0.8180\n",
            "Epoch 159/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0046 - accuracy: 0.7443 - val_loss: 0.5529 - val_accuracy: 0.8309\n",
            "Epoch 160/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.0072 - accuracy: 0.7437 - val_loss: 0.5726 - val_accuracy: 0.8229\n",
            "Epoch 161/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 1.0057 - accuracy: 0.7455 - val_loss: 0.5643 - val_accuracy: 0.8287\n",
            "Epoch 162/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0015 - accuracy: 0.7451 - val_loss: 0.5762 - val_accuracy: 0.8235\n",
            "Epoch 163/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0004 - accuracy: 0.7435 - val_loss: 0.5737 - val_accuracy: 0.8220\n",
            "Epoch 164/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 0.9997 - accuracy: 0.7452 - val_loss: 0.5971 - val_accuracy: 0.8136\n",
            "Epoch 165/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9993 - accuracy: 0.7449 - val_loss: 0.5770 - val_accuracy: 0.8215\n",
            "Epoch 166/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0001 - accuracy: 0.7440 - val_loss: 0.5546 - val_accuracy: 0.8291\n",
            "Epoch 167/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 1.0000 - accuracy: 0.7455 - val_loss: 0.5604 - val_accuracy: 0.8301\n",
            "Epoch 168/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9896 - accuracy: 0.7487 - val_loss: 0.5670 - val_accuracy: 0.8260\n",
            "Epoch 169/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9931 - accuracy: 0.7472 - val_loss: 0.5687 - val_accuracy: 0.8240\n",
            "Epoch 170/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 0.9883 - accuracy: 0.7491 - val_loss: 0.5489 - val_accuracy: 0.8315\n",
            "Epoch 171/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9879 - accuracy: 0.7481 - val_loss: 0.5781 - val_accuracy: 0.8208\n",
            "Epoch 172/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9869 - accuracy: 0.7488 - val_loss: 0.5667 - val_accuracy: 0.8276\n",
            "Epoch 173/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9904 - accuracy: 0.7465 - val_loss: 0.5568 - val_accuracy: 0.8303\n",
            "Epoch 174/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 0.9855 - accuracy: 0.7496 - val_loss: 0.5661 - val_accuracy: 0.8260\n",
            "Epoch 175/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 0.9860 - accuracy: 0.7482 - val_loss: 0.5784 - val_accuracy: 0.8219\n",
            "Epoch 176/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9848 - accuracy: 0.7485 - val_loss: 0.5672 - val_accuracy: 0.8245\n",
            "Epoch 177/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9900 - accuracy: 0.7485 - val_loss: 0.5661 - val_accuracy: 0.8272\n",
            "Epoch 178/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9831 - accuracy: 0.7492 - val_loss: 0.5561 - val_accuracy: 0.8308\n",
            "Epoch 179/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9833 - accuracy: 0.7481 - val_loss: 0.5714 - val_accuracy: 0.8216\n",
            "Epoch 180/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9791 - accuracy: 0.7493 - val_loss: 0.5477 - val_accuracy: 0.8332\n",
            "Epoch 181/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9818 - accuracy: 0.7519 - val_loss: 0.5559 - val_accuracy: 0.8307\n",
            "Epoch 182/250\n",
            "1406/1406 [==============================] - 26s 19ms/step - loss: 0.9780 - accuracy: 0.7508 - val_loss: 0.5416 - val_accuracy: 0.8333\n",
            "Epoch 183/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9787 - accuracy: 0.7491 - val_loss: 0.6168 - val_accuracy: 0.8119\n",
            "Epoch 184/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9760 - accuracy: 0.7531 - val_loss: 0.5506 - val_accuracy: 0.8287\n",
            "Epoch 185/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9791 - accuracy: 0.7500 - val_loss: 0.5600 - val_accuracy: 0.8256\n",
            "Epoch 186/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9772 - accuracy: 0.7527 - val_loss: 0.5592 - val_accuracy: 0.8275\n",
            "Epoch 187/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9710 - accuracy: 0.7532 - val_loss: 0.5653 - val_accuracy: 0.8249\n",
            "Epoch 188/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9735 - accuracy: 0.7538 - val_loss: 0.5495 - val_accuracy: 0.8313\n",
            "Epoch 189/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9674 - accuracy: 0.7540 - val_loss: 0.5560 - val_accuracy: 0.8323\n",
            "Epoch 190/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9688 - accuracy: 0.7541 - val_loss: 0.5690 - val_accuracy: 0.8260\n",
            "Epoch 191/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9731 - accuracy: 0.7531 - val_loss: 0.5387 - val_accuracy: 0.8343\n",
            "Epoch 192/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9693 - accuracy: 0.7544 - val_loss: 0.5504 - val_accuracy: 0.8316\n",
            "Epoch 193/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9701 - accuracy: 0.7551 - val_loss: 0.5395 - val_accuracy: 0.8351\n",
            "Epoch 194/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9708 - accuracy: 0.7547 - val_loss: 0.5526 - val_accuracy: 0.8317\n",
            "Epoch 195/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9662 - accuracy: 0.7541 - val_loss: 0.5595 - val_accuracy: 0.8276\n",
            "Epoch 196/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9651 - accuracy: 0.7541 - val_loss: 0.5529 - val_accuracy: 0.8316\n",
            "Epoch 197/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9603 - accuracy: 0.7571 - val_loss: 0.5438 - val_accuracy: 0.8316\n",
            "Epoch 198/250\n",
            "1406/1406 [==============================] - 27s 20ms/step - loss: 0.9619 - accuracy: 0.7542 - val_loss: 0.5470 - val_accuracy: 0.8340\n",
            "Epoch 199/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9639 - accuracy: 0.7547 - val_loss: 0.5499 - val_accuracy: 0.8329\n",
            "Epoch 200/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9561 - accuracy: 0.7586 - val_loss: 0.5340 - val_accuracy: 0.8373\n",
            "Epoch 201/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9655 - accuracy: 0.7564 - val_loss: 0.5424 - val_accuracy: 0.8351\n",
            "Epoch 202/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9636 - accuracy: 0.7555 - val_loss: 0.5578 - val_accuracy: 0.8308\n",
            "Epoch 203/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9592 - accuracy: 0.7580 - val_loss: 0.5715 - val_accuracy: 0.8236\n",
            "Epoch 204/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9572 - accuracy: 0.7566 - val_loss: 0.5644 - val_accuracy: 0.8288\n",
            "Epoch 205/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9570 - accuracy: 0.7556 - val_loss: 0.5528 - val_accuracy: 0.8315\n",
            "Epoch 206/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9610 - accuracy: 0.7556 - val_loss: 0.5629 - val_accuracy: 0.8280\n",
            "Epoch 207/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9569 - accuracy: 0.7580 - val_loss: 0.5454 - val_accuracy: 0.8312\n",
            "Epoch 208/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9568 - accuracy: 0.7574 - val_loss: 0.5348 - val_accuracy: 0.8380\n",
            "Epoch 209/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9512 - accuracy: 0.7574 - val_loss: 0.5451 - val_accuracy: 0.8317\n",
            "Epoch 210/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9585 - accuracy: 0.7568 - val_loss: 0.5304 - val_accuracy: 0.8385\n",
            "Epoch 211/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9546 - accuracy: 0.7571 - val_loss: 0.5408 - val_accuracy: 0.8357\n",
            "Epoch 212/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9510 - accuracy: 0.7589 - val_loss: 0.5399 - val_accuracy: 0.8371\n",
            "Epoch 213/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9459 - accuracy: 0.7624 - val_loss: 0.5568 - val_accuracy: 0.8273\n",
            "Epoch 214/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9457 - accuracy: 0.7608 - val_loss: 0.5418 - val_accuracy: 0.8335\n",
            "Epoch 215/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9484 - accuracy: 0.7603 - val_loss: 0.5397 - val_accuracy: 0.8384\n",
            "Epoch 216/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9475 - accuracy: 0.7605 - val_loss: 0.5269 - val_accuracy: 0.8428\n",
            "Epoch 217/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9465 - accuracy: 0.7622 - val_loss: 0.5545 - val_accuracy: 0.8297\n",
            "Epoch 218/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9506 - accuracy: 0.7595 - val_loss: 0.5458 - val_accuracy: 0.8355\n",
            "Epoch 219/250\n",
            "1406/1406 [==============================] - 27s 20ms/step - loss: 0.9428 - accuracy: 0.7598 - val_loss: 0.5545 - val_accuracy: 0.8325\n",
            "Epoch 220/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9429 - accuracy: 0.7606 - val_loss: 0.5305 - val_accuracy: 0.8387\n",
            "Epoch 221/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9428 - accuracy: 0.7581 - val_loss: 0.5206 - val_accuracy: 0.8448\n",
            "Epoch 222/250\n",
            "1406/1406 [==============================] - 27s 20ms/step - loss: 0.9417 - accuracy: 0.7611 - val_loss: 0.5371 - val_accuracy: 0.8381\n",
            "Epoch 223/250\n",
            "1406/1406 [==============================] - 27s 20ms/step - loss: 0.9427 - accuracy: 0.7614 - val_loss: 0.5319 - val_accuracy: 0.8392\n",
            "Epoch 224/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9389 - accuracy: 0.7621 - val_loss: 0.5297 - val_accuracy: 0.8363\n",
            "Epoch 225/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9397 - accuracy: 0.7615 - val_loss: 0.5337 - val_accuracy: 0.8348\n",
            "Epoch 226/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9355 - accuracy: 0.7629 - val_loss: 0.5514 - val_accuracy: 0.8348\n",
            "Epoch 227/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9388 - accuracy: 0.7614 - val_loss: 0.5277 - val_accuracy: 0.8391\n",
            "Epoch 228/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9405 - accuracy: 0.7611 - val_loss: 0.5459 - val_accuracy: 0.8359\n",
            "Epoch 229/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9410 - accuracy: 0.7637 - val_loss: 0.5286 - val_accuracy: 0.8408\n",
            "Epoch 230/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9336 - accuracy: 0.7631 - val_loss: 0.5475 - val_accuracy: 0.8328\n",
            "Epoch 231/250\n",
            "1406/1406 [==============================] - 27s 20ms/step - loss: 0.9426 - accuracy: 0.7621 - val_loss: 0.5226 - val_accuracy: 0.8411\n",
            "Epoch 232/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9463 - accuracy: 0.7617 - val_loss: 0.5303 - val_accuracy: 0.8375\n",
            "Epoch 233/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9343 - accuracy: 0.7632 - val_loss: 0.5290 - val_accuracy: 0.8384\n",
            "Epoch 234/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9359 - accuracy: 0.7617 - val_loss: 0.5346 - val_accuracy: 0.8384\n",
            "Epoch 235/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9306 - accuracy: 0.7641 - val_loss: 0.5172 - val_accuracy: 0.8433\n",
            "Epoch 236/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9309 - accuracy: 0.7649 - val_loss: 0.5398 - val_accuracy: 0.8375\n",
            "Epoch 237/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9288 - accuracy: 0.7656 - val_loss: 0.5224 - val_accuracy: 0.8409\n",
            "Epoch 238/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9259 - accuracy: 0.7665 - val_loss: 0.5267 - val_accuracy: 0.8407\n",
            "Epoch 239/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9339 - accuracy: 0.7640 - val_loss: 0.5248 - val_accuracy: 0.8413\n",
            "Epoch 240/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9292 - accuracy: 0.7661 - val_loss: 0.5418 - val_accuracy: 0.8343\n",
            "Epoch 241/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9281 - accuracy: 0.7668 - val_loss: 0.5251 - val_accuracy: 0.8403\n",
            "Epoch 242/250\n",
            "1406/1406 [==============================] - 27s 19ms/step - loss: 0.9279 - accuracy: 0.7672 - val_loss: 0.5379 - val_accuracy: 0.8363\n",
            "Epoch 243/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9294 - accuracy: 0.7637 - val_loss: 0.5290 - val_accuracy: 0.8371\n",
            "Epoch 244/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9240 - accuracy: 0.7669 - val_loss: 0.5351 - val_accuracy: 0.8365\n",
            "Epoch 245/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9243 - accuracy: 0.7647 - val_loss: 0.5126 - val_accuracy: 0.8443\n",
            "Epoch 246/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9193 - accuracy: 0.7701 - val_loss: 0.5497 - val_accuracy: 0.8344\n",
            "Epoch 247/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9298 - accuracy: 0.7639 - val_loss: 0.5327 - val_accuracy: 0.8393\n",
            "Epoch 248/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9181 - accuracy: 0.7685 - val_loss: 0.5247 - val_accuracy: 0.8440\n",
            "Epoch 249/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9213 - accuracy: 0.7678 - val_loss: 0.5309 - val_accuracy: 0.8388\n",
            "Epoch 250/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9225 - accuracy: 0.7664 - val_loss: 0.5359 - val_accuracy: 0.8376\n",
            "704/704 [==============================] - 3s 4ms/step - loss: 0.5149 - accuracy: 0.8430\n",
            "> 84.302\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}